{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "haikus = []\n",
    "for file_path in glob.glob('model_4_/*.txt'):\n",
    "# for file_path in glob.glob('words_with_syllable_count_then_training_with_haiku_dataset_with_syllable_count_/*.txt'):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if '|' in line:\n",
    "                _, haiku = line.strip().split('|')\n",
    "                haiku = [x.strip() for x in haiku.split('/')]\n",
    "                haiku = ' /n '.join(haiku)\n",
    "                haikus.append(haiku)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output4.txt','w',encoding='utf-8') as fo:\n",
    "    for haiku in haikus:\n",
    "        fo.write(haiku + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "haikus = []\n",
    "# for file_path in glob.glob('words_with_syllable_count_then_training_with_haiku_dataset_with_syllable_count_/*.txt'):\n",
    "with open('loweredcase.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        _, haiku = line.strip().split('|')\n",
    "        haiku = [x.strip() for x in haiku.split('/')]\n",
    "        haiku = ' /n '.join(haiku)\n",
    "        haikus.append(haiku)\n",
    "with open('baseline_eval.txt','w',encoding='utf-8') as fo:\n",
    "    for haiku in haikus:\n",
    "        fo.write(haiku + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1_ 403 0.41935483870967744\n",
      "model_2_ 508 0.5090180360721442\n",
      "model_3_ 484 0.4864321608040201\n",
      "model_4_ 658 0.6639757820383451\n",
      "baseline_ 613 0.6179435483870968\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "import syllables\n",
    "import glob\n",
    "\n",
    "folders = ['model_1_','model_2_','model_3_','model_4_','baseline_']\n",
    "for folder in folders:\n",
    "    haikus = []\n",
    "    syllables_cnt =[]\n",
    "    for file_path in glob.glob(folder+'/*.txt'):\n",
    "        with open(file_path, encoding='utf-8') as f:\n",
    "            if folder == 'baseline_':\n",
    "                for line in f:\n",
    "                    if '/' in line:\n",
    "                        haiku = [x.strip() for x in line.strip().split('/')]\n",
    "                        cnt = [syllables.estimate(stanza) for stanza in haiku]\n",
    "                        if len(haiku) < 3:\n",
    "                            continue\n",
    "                        # haiku = ' /n '.join(haiku)\n",
    "                        haikus.append(haiku)\n",
    "                        syllables_cnt.append(cnt)\n",
    "            else:\n",
    "                for line in f:\n",
    "                    if '|' in line:\n",
    "                        _, haiku = line.strip().split('|')\n",
    "                        haiku = [x.strip() for x in haiku.split('/')]\n",
    "                        cnt = [syllables.estimate(stanza) for stanza in haiku]\n",
    "                        if len(haiku) < 3:\n",
    "                            continue\n",
    "                        # haiku = ' /n '.join(haiku)\n",
    "                        haikus.append(haiku)\n",
    "                        syllables_cnt.append(cnt)\n",
    "                    \n",
    "    score = 0\n",
    "    for cnt in syllables_cnt:\n",
    "        if 5 <= cnt[0] <= 7 and 7 <= cnt[1] <= 9 and 5 <= cnt[2] <= 7:\n",
    "            score += 1\n",
    "    print(folder, score, score / len(syllables_cnt))\n",
    "\n",
    "    with open(f'output_{folder}_cnt.txt','w',encoding='utf-8') as fo:\n",
    "        for cnt, haiku in zip(syllables_cnt, haikus):\n",
    "            cnt = ','.join([str(x) for x in cnt])\n",
    "            haiku = ' /n '.join(haiku)\n",
    "            fo.write('{} | {} \\n'.format(cnt, haiku))\n",
    "# haikus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_haikus = []\n",
    "baseline_cnt = []\n",
    "with open('baseline.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # if '|' in line:\n",
    "            # _, haiku = line.strip().split('|')\n",
    "            haiku = line.strip()\n",
    "            haiku = [x.strip() for x in haiku.split('/')]\n",
    "            cnt = [syllables.estimate(stanza) for stanza in haiku]\n",
    "            # if len(haiku) < 3:\n",
    "            #     continue\n",
    "            # haiku = ' /n '.join(haiku)\n",
    "\n",
    "            baseline_haikus.append(haiku)\n",
    "            baseline_cnt.append(cnt)\n",
    "            \n",
    "# baseline_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'output_baseline_cnt.txt','w',encoding='utf-8') as fo:\n",
    "    for cnt, haiku in zip(baseline_cnt, baseline_haikus):\n",
    "        cnt = ','.join([str(x) for x in cnt])\n",
    "        haiku = ' /n '.join(haiku)\n",
    "        fo.write('{} | {} \\n'.format(cnt, haiku))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a36de45f9eafbca8e6b28b7cbdad23baeccb2be7ea045f640cf073e9655bccd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

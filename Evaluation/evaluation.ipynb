{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7NWAqyp1l9HcB3h04Wqt+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergior2/CSCI544-Final-Report/blob/main/Evaluation/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "NFvkqiTtUQH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJBzNaYLl39s",
        "outputId": "5ddf7fa5-185b-44dd-b563-199d93ad11c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/haikus.csv\")"
      ],
      "metadata": {
        "id": "DCjRptsPmCJY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeZkkBrimU_I",
        "outputId": "e08669ae-0bb6-435a-a6e2-db541fd0c688"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143137, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "4XuwvKLsnKa0",
        "outputId": "e49aca41-9029-426c-ec8b-bada0e370b1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   0                     1                  2       source  \\\n",
              "0    Memorial Day --     a shadow for each        white cross  tempslibres   \n",
              "1      spring rain -  as the doctor speaks  i think of lilacs  tempslibres   \n",
              "2  spring moonset --       a rice ball for          breakfast  tempslibres   \n",
              "3    sunny afternoon    an old man lingers   near the mailbox  tempslibres   \n",
              "4      cinco de mayo           horses roll    in the shallows  tempslibres   \n",
              "\n",
              "  0_syllables 1_syllables 2_syllables  \n",
              "0           5           5           2  \n",
              "1         2,3           5           5  \n",
              "2         3,4           4           2  \n",
              "3           5           5           4  \n",
              "4           5           3           4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2da20cf9-0b50-49d2-ad48-6cf30df86017\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>source</th>\n",
              "      <th>0_syllables</th>\n",
              "      <th>1_syllables</th>\n",
              "      <th>2_syllables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Memorial Day --</td>\n",
              "      <td>a shadow for each</td>\n",
              "      <td>white cross</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spring rain -</td>\n",
              "      <td>as the doctor speaks</td>\n",
              "      <td>i think of lilacs</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>2,3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spring moonset --</td>\n",
              "      <td>a rice ball for</td>\n",
              "      <td>breakfast</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>3,4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sunny afternoon</td>\n",
              "      <td>an old man lingers</td>\n",
              "      <td>near the mailbox</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cinco de mayo</td>\n",
              "      <td>horses roll</td>\n",
              "      <td>in the shallows</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da20cf9-0b50-49d2-ad48-6cf30df86017')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2da20cf9-0b50-49d2-ad48-6cf30df86017 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2da20cf9-0b50-49d2-ad48-6cf30df86017');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_575 = data[(data[\"0_syllables\"] == \"5\") & (data[\"1_syllables\"] == \"7\")  & (data[\"2_syllables\"] == \"5\")]"
      ],
      "metadata": {
        "id": "GYxcABDunHiX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_575.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8-YPdXFncLr",
        "outputId": "668bb0bc-cbb9-477b-cc47-75df655dfe38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93390, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_575.head()\n",
        "data_575.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "euI7QaB3ndRF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_575.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "r_rApCGpnuaJ",
        "outputId": "f370a4ec-217a-43ac-ec62-512b1eb40af2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        0                                   1  \\\n",
              "0     last red in the sky      a small girl's moon face rises   \n",
              "1      christmas services          a cellular phone rings out   \n",
              "2     Passover darkness -         before the buds burst open;   \n",
              "3    Last night of Summer  the bright full moon of last night   \n",
              "4  Midnight and full moon         my neighbour asks to borrow   \n",
              "\n",
              "                          2       source 0_syllables 1_syllables 2_syllables  \n",
              "0          over the counter  tempslibres           5           7           5  \n",
              "1          handel's messiah  tempslibres           5           7           5  \n",
              "2  a child's eyes in death.  tempslibres           5           7           5  \n",
              "3         hidden by a cloud  tempslibres           5           7           5  \n",
              "4         the vacum cleaner  tempslibres           5           7           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35eb8c34-164a-4111-91bb-6dd9060658e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>source</th>\n",
              "      <th>0_syllables</th>\n",
              "      <th>1_syllables</th>\n",
              "      <th>2_syllables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>last red in the sky</td>\n",
              "      <td>a small girl's moon face rises</td>\n",
              "      <td>over the counter</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>christmas services</td>\n",
              "      <td>a cellular phone rings out</td>\n",
              "      <td>handel's messiah</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Passover darkness -</td>\n",
              "      <td>before the buds burst open;</td>\n",
              "      <td>a child's eyes in death.</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Last night of Summer</td>\n",
              "      <td>the bright full moon of last night</td>\n",
              "      <td>hidden by a cloud</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Midnight and full moon</td>\n",
              "      <td>my neighbour asks to borrow</td>\n",
              "      <td>the vacum cleaner</td>\n",
              "      <td>tempslibres</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35eb8c34-164a-4111-91bb-6dd9060658e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35eb8c34-164a-4111-91bb-6dd9060658e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35eb8c34-164a-4111-91bb-6dd9060658e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_575 = data_575.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "K9z0G50KsI45"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_575.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "60aDHErWsqM5",
        "outputId": "ae43b397-f2e8-45fb-aa09-9c865e8f8bf1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        0                              1  \\\n",
              "0   You don't give people   the reaction they want watch   \n",
              "1   Still waiting for the           day I get taken on a   \n",
              "2  Thankful I know what's    best for me and that I know   \n",
              "3       I'm so tired it's    so late I cried tonight and   \n",
              "4        hating is a full      time job rather get under   \n",
              "\n",
              "                         2  source 0_syllables 1_syllables 2_syllables  \n",
              "0      that shit eat em up  twaiku           5           7           5  \n",
              "1     date to Barnes Noble  twaiku           5           7           5  \n",
              "2        when to walk away  twaiku           5           7           5  \n",
              "3  now it's time for sLEEP  twaiku           5           7           5  \n",
              "4   your skin with a smile  twaiku           5           7           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-338362ee-e29d-4165-966d-15f4b3f320d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>source</th>\n",
              "      <th>0_syllables</th>\n",
              "      <th>1_syllables</th>\n",
              "      <th>2_syllables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You don't give people</td>\n",
              "      <td>the reaction they want watch</td>\n",
              "      <td>that shit eat em up</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Still waiting for the</td>\n",
              "      <td>day I get taken on a</td>\n",
              "      <td>date to Barnes Noble</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thankful I know what's</td>\n",
              "      <td>best for me and that I know</td>\n",
              "      <td>when to walk away</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm so tired it's</td>\n",
              "      <td>so late I cried tonight and</td>\n",
              "      <td>now it's time for sLEEP</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hating is a full</td>\n",
              "      <td>time job rather get under</td>\n",
              "      <td>your skin with a smile</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-338362ee-e29d-4165-966d-15f4b3f320d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-338362ee-e29d-4165-966d-15f4b3f320d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-338362ee-e29d-4165-966d-15f4b3f320d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_575[\"0\"] = data_575[\"0\"].apply(lambda x: x.lower())\n",
        "data_575[\"1\"] = data_575[\"1\"].apply(lambda x: x.lower())\n",
        "data_575[\"2\"] = data_575[\"2\"].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "MhqAVj6ZIp5V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_575 = data_575.apply(lambda x: \"/n\".join([x[0], x[1], x[2]]).lower(), axis=1)"
      ],
      "metadata": {
        "id": "-hfGO9WGtLMZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = data_575.apply(lambda x: x[\"0\"].split() + x[\"1\"].split() + x[\"2\"].split(), axis=1)\n",
        "vocab = []\n",
        "for w in words:\n",
        "  vocab += w\n",
        "\n",
        "words, counts = np.unique(vocab, return_counts=True)"
      ],
      "metadata": {
        "id": "oMz_O4yU8SBD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tnuT5qfSN-Pn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_575_sample = data_575.loc[:5999]"
      ],
      "metadata": {
        "id": "7u1PiFTx0Kdg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_575_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs1ZQgsN0VJ_",
        "outputId": "ff0b2686-8700-4dc3-a4e0-d43cf2d86e19"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits = np.split(data_575_sample, 2)"
      ],
      "metadata": {
        "id": "rCm5CkYSn6sB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_0 = splits[0]\n",
        "noise_30 = splits[1]"
      ],
      "metadata": {
        "id": "LUZeHKd3ruhU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_30.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "jb7ROHaqtJBe",
        "outputId": "50c87fea-2639-4826-828f-3e1cb8bd0d76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        0                               1  \\\n",
              "3000  we're going to look             at a venue tomorrow   \n",
              "3001    the apartments in          baltimore city make me   \n",
              "3002         loyalty over         love any day everything   \n",
              "3003  if someone you hate    for no reason that means you   \n",
              "3004  good morning well i   guess it's afternoon now what   \n",
              "\n",
              "                            2  source 0_syllables 1_syllables 2_syllables  \n",
              "3000         and i'm so happy  twaiku           5           7           5  \n",
              "3001     wanna move out there  twaiku           5           7           5  \n",
              "3002  else will fall in place  twaiku           5           7           5  \n",
              "3003    had feelings for them  twaiku           5           7           5  \n",
              "3004   should i get for lunch  twaiku           5           7           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50a36b01-9f47-4f5a-9018-299701bcc40e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>source</th>\n",
              "      <th>0_syllables</th>\n",
              "      <th>1_syllables</th>\n",
              "      <th>2_syllables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>we're going to look</td>\n",
              "      <td>at a venue tomorrow</td>\n",
              "      <td>and i'm so happy</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3001</th>\n",
              "      <td>the apartments in</td>\n",
              "      <td>baltimore city make me</td>\n",
              "      <td>wanna move out there</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002</th>\n",
              "      <td>loyalty over</td>\n",
              "      <td>love any day everything</td>\n",
              "      <td>else will fall in place</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3003</th>\n",
              "      <td>if someone you hate</td>\n",
              "      <td>for no reason that means you</td>\n",
              "      <td>had feelings for them</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3004</th>\n",
              "      <td>good morning well i</td>\n",
              "      <td>guess it's afternoon now what</td>\n",
              "      <td>should i get for lunch</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50a36b01-9f47-4f5a-9018-299701bcc40e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50a36b01-9f47-4f5a-9018-299701bcc40e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50a36b01-9f47-4f5a-9018-299701bcc40e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace(data, share, vocab):\n",
        "  texts = data.apply(lambda x: x[\"0\"].split() + x[\"1\"].split() + x[\"2\"].split(), axis=1).values\n",
        "  sizes = [len(t) for t in texts]\n",
        "  line_sizes = data.apply(lambda x: [len(x[\"0\"].split()), len(x[\"1\"].split()), len(x[\"2\"].split())], axis=1).values\n",
        "  indices = [np.random.choice(np.arange(s), size=int(np.floor(share * s)), replace=False) for s in sizes]\n",
        "  first = []\n",
        "  second = []\n",
        "  third = []\n",
        "  for i in tqdm(range(len(indices))):\n",
        "    for j in indices[i]:\n",
        "      texts[i][j] = np.random.choice(vocab)\n",
        "      # a = 1\n",
        "    first.append(\" \".join(texts[i][:line_sizes[i][0]]))\n",
        "    second.append(\" \".join(texts[i][line_sizes[i][0]:line_sizes[i][0]+line_sizes[i][1]]))\n",
        "    third.append(\" \".join(texts[i][line_sizes[i][0] + line_sizes[i][1]:]))\n",
        "\n",
        "  data[\"0\"] = first\n",
        "  data[\"1\"] = second\n",
        "  data[\"2\"] = third\n",
        "\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "uu7V_Gg_di2o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_30 = replace(noise_30, 0.3, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpbkJNOLsCvC",
        "outputId": "ecbd02b5-9597-40d0-9b1e-3e86045175ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [36:30<00:00,  1.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_0.to_csv(\"gdrive/MyDrive/Colab Notebooks/zero_noise_bin.csv\", index=False)\n",
        "noise_30.to_csv(\"gdrive/MyDrive/Colab Notebooks/30_noise_bin.csv\", index=False)"
      ],
      "metadata": {
        "id": "S2sXcs-ZAsxb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_0.to_csv(\"zero_noise.csv\", index=False)\n",
        "noise_30.to_csv(\"30_noise.csv\", index=False)\n",
        "noise_60.to_csv(\"60_noise.csv\", index=False)"
      ],
      "metadata": {
        "id": "xaCabAhLCarc"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_30.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "0KsoM-h6wHPO",
        "outputId": "8b333728-5ec2-4fbd-cc5f-c6eca2c9ce55"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           0                                  1  \\\n",
              "3000      we're some to look           already a venue tomorrow   \n",
              "3001       the apartments in                  poor city make me   \n",
              "3002            loyalty that         love things day everything   \n",
              "3003    nine someone so hate  for no reason interrupt means you   \n",
              "3004  friends morning well i      guess it's afternoon now what   \n",
              "\n",
              "                              2  source 0_syllables 1_syllables 2_syllables  \n",
              "3000           and but so happy  twaiku           5           7           5  \n",
              "3001         wanna yet out over  twaiku           5           7           5  \n",
              "3002  people will fall in place  twaiku           5           7           5  \n",
              "3003       had working for them  twaiku           5           7           5  \n",
              "3004     over his get man lunch  twaiku           5           7           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-952381ca-aee0-4460-a3cb-0f68b77e9ebb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>source</th>\n",
              "      <th>0_syllables</th>\n",
              "      <th>1_syllables</th>\n",
              "      <th>2_syllables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>we're some to look</td>\n",
              "      <td>already a venue tomorrow</td>\n",
              "      <td>and but so happy</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3001</th>\n",
              "      <td>the apartments in</td>\n",
              "      <td>poor city make me</td>\n",
              "      <td>wanna yet out over</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002</th>\n",
              "      <td>loyalty that</td>\n",
              "      <td>love things day everything</td>\n",
              "      <td>people will fall in place</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3003</th>\n",
              "      <td>nine someone so hate</td>\n",
              "      <td>for no reason interrupt means you</td>\n",
              "      <td>had working for them</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3004</th>\n",
              "      <td>friends morning well i</td>\n",
              "      <td>guess it's afternoon now what</td>\n",
              "      <td>over his get man lunch</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-952381ca-aee0-4460-a3cb-0f68b77e9ebb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-952381ca-aee0-4460-a3cb-0f68b77e9ebb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-952381ca-aee0-4460-a3cb-0f68b77e9ebb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________"
      ],
      "metadata": {
        "id": "dwPbD5hle4RR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ],
      "metadata": {
        "id": "lzVTMC_-UUL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUehbfygntfq",
        "outputId": "125ad86f-35c0-41fb-eab1-29c50c055c7c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_0_bin = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/zero_noise_bin.csv\")\n",
        "noise_30_bin = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/30_noise_bin.csv\")\n",
        "\n",
        "noise_0_bin[\"label\"] = 0\n",
        "noise_30_bin[\"label\"] = 1\n",
        "\n",
        "data_bin = pd.concat([noise_0_bin, noise_30_bin], axis=0)\n",
        "\n",
        "data_bin[\"text\"] = data_bin.apply(lambda x: \"\\n\".join([x[\"0\"], x[\"1\"], x[\"2\"]]), axis=1)\n",
        "\n",
        "data_bin.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "-UXjRKKyE9go",
        "outputId": "dabb02d4-5eb2-4456-c505-55fcf862b611"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        0                              1  \\\n",
              "0   you don't give people   the reaction they want watch   \n",
              "1   still waiting for the           day i get taken on a   \n",
              "2  thankful i know what's    best for me and that i know   \n",
              "3       i'm so tired it's    so late i cried tonight and   \n",
              "4        hating is a full      time job rather get under   \n",
              "\n",
              "                         2  source  0_syllables  1_syllables  2_syllables  \\\n",
              "0      that shit eat em up  twaiku            5            7            5   \n",
              "1     date to barnes noble  twaiku            5            7            5   \n",
              "2        when to walk away  twaiku            5            7            5   \n",
              "3  now it's time for sleep  twaiku            5            7            5   \n",
              "4   your skin with a smile  twaiku            5            7            5   \n",
              "\n",
              "   label                                               text  \n",
              "0      0  you don't give people\\n the reaction they want...  \n",
              "1      0  still waiting for the\\n day i get taken on a\\n...  \n",
              "2      0  thankful i know what's\\n best for me and that ...  \n",
              "3      0  i'm so tired it's\\n so late i cried tonight an...  \n",
              "4      0  hating is a full\\n time job rather get under\\n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff766fd4-5962-4dfc-becc-8fbf491ae990\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>source</th>\n",
              "      <th>0_syllables</th>\n",
              "      <th>1_syllables</th>\n",
              "      <th>2_syllables</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you don't give people</td>\n",
              "      <td>the reaction they want watch</td>\n",
              "      <td>that shit eat em up</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>you don't give people\\n the reaction they want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>still waiting for the</td>\n",
              "      <td>day i get taken on a</td>\n",
              "      <td>date to barnes noble</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>still waiting for the\\n day i get taken on a\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thankful i know what's</td>\n",
              "      <td>best for me and that i know</td>\n",
              "      <td>when to walk away</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>thankful i know what's\\n best for me and that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i'm so tired it's</td>\n",
              "      <td>so late i cried tonight and</td>\n",
              "      <td>now it's time for sleep</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>i'm so tired it's\\n so late i cried tonight an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hating is a full</td>\n",
              "      <td>time job rather get under</td>\n",
              "      <td>your skin with a smile</td>\n",
              "      <td>twaiku</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>hating is a full\\n time job rather get under\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff766fd4-5962-4dfc-becc-8fbf491ae990')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff766fd4-5962-4dfc-becc-8fbf491ae990 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff766fd4-5962-4dfc-becc-8fbf491ae990');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Classificator**"
      ],
      "metadata": {
        "id": "KiLiUUMOgSwF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cRE8IbIrIV"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db62b5a-32e9-49e1-d9f5-c729ac8dc5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random"
      ],
      "metadata": {
        "id": "43pPCbzckaLx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = data_bin.text.values\n",
        "labels = data_bin.label.values"
      ],
      "metadata": {
        "id": "Be_2Rltsj-Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case = True,\n",
        "    # sep_token = \"\\n\"\n",
        "    )"
      ],
      "metadata": {
        "id": "s1rznzyOkR_S"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_rand_sentence():\n",
        "  '''Displays the tokens and respective IDs of a random text sample'''\n",
        "  index = random.randint(0, len(text)-1)\n",
        "  table = np.array([tokenizer.tokenize(text[index]), \n",
        "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
        "  print(tabulate(table,\n",
        "                 headers = ['Tokens', 'Token IDs'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RX_EF-9kvJf",
        "outputId": "be68e76c-b4de-4b35-c155-e6e945211905"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════╤═════════════╕\n",
            "│ Tokens   │   Token IDs │\n",
            "╞══════════╪═════════════╡\n",
            "│ goodness │       15003 │\n",
            "├──────────┼─────────────┤\n",
            "│ those    │        2216 │\n",
            "├──────────┼─────────────┤\n",
            "│ chi      │        9610 │\n",
            "├──────────┼─────────────┤\n",
            "│ ##a      │        2050 │\n",
            "├──────────┼─────────────┤\n",
            "│ seeds    │        8079 │\n",
            "├──────────┼─────────────┤\n",
            "│ have     │        2031 │\n",
            "├──────────┼─────────────┤\n",
            "│ really   │        2428 │\n",
            "├──────────┼─────────────┤\n",
            "│ filled   │        3561 │\n",
            "├──────────┼─────────────┤\n",
            "│ me       │        2033 │\n",
            "├──────────┼─────────────┤\n",
            "│ up       │        2039 │\n",
            "├──────────┼─────────────┤\n",
            "│ said     │        2056 │\n",
            "├──────────┼─────────────┤\n",
            "│ no       │        2053 │\n",
            "├──────────┼─────────────┤\n",
            "│ one      │        2028 │\n",
            "├──────────┼─────────────┤\n",
            "│ ever     │        2412 │\n",
            "╘══════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 32,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "for sample in text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "serg-ywDlDnL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_id[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y69Lkrt7lXF1",
        "outputId": "038f172f-bc18-408b-d20e-739935f7c75c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  2619,  2175,  2000, 20877,  2007,  2033,  2061,  2026,  2905,\n",
              "         2097,  3844,  2039,  2055,  2009,   102,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def print_rand_sentence_encoding():\n",
        "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
        "  index = random.randint(0, len(text) - 1)\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
        "  token_ids = [i.numpy() for i in token_id[index]]\n",
        "  attention = [i.numpy() for i in attention_masks[index]]\n",
        "\n",
        "  table = np.array([tokens, token_ids, attention]).T\n",
        "  print(tabulate(table, \n",
        "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence_encoding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uic8S9cTlovC",
        "outputId": "582808a0-9239-449d-8f90-3ca25c8d897f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════╤═════════════╤══════════════════╕\n",
            "│ Tokens   │   Token IDs │   Attention Mask │\n",
            "╞══════════╪═════════════╪══════════════════╡\n",
            "│ [CLS]    │         101 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ i        │        1045 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ was      │        2001 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ going    │        2183 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ to       │        2000 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ tell     │        2425 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ you      │        2017 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ about    │        2055 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ my       │        2026 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ hai      │       15030 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ ##ku     │        5283 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ problem  │        3291 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ this     │        2023 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ happened │        3047 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [SEP]    │         102 │                1 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "├──────────┼─────────────┼──────────────────┤\n",
            "│ [PAD]    │           0 │                0 │\n",
            "╘══════════╧═════════════╧══════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ratio = 0.2\n",
        "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "batch_size = 16\n",
        "\n",
        "# Indices of the train and validation splits stratified by labels\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(labels)),\n",
        "    test_size = val_ratio,\n",
        "    shuffle = True,\n",
        "    stratify = labels)\n",
        "\n",
        "# Train and validation sets\n",
        "train_set = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "val_set = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])\n",
        "\n",
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_set,\n",
        "            sampler = RandomSampler(train_set),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_set,\n",
        "            sampler = SequentialSampler(val_set),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "3cOSkqBImejM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds > 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds > 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "K1nSCROumimf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 5e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE6YEiexnACO",
        "outputId": "93fdeda0-2095-4b0c-b77c-8615b87a1d42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 2\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxk4_0AKnNQW",
        "outputId": "5e91897d-3455-44d0-8f25-babad21cdabc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  50%|█████     | 1/2 [00:38<00:38, 38.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.2535\n",
            "\t - Validation Accuracy: 0.9167\n",
            "\t - Validation Precision: 0.9037\n",
            "\t - Validation Recall: 0.9330\n",
            "\t - Validation Specificity: 0.8981\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 2/2 [01:17<00:00, 38.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.0666\n",
            "\t - Validation Accuracy: 0.9033\n",
            "\t - Validation Precision: 0.8797\n",
            "\t - Validation Recall: 0.9276\n",
            "\t - Validation Specificity: 0.8758\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "haiku = 'apples of paradise\\nviolently shake in the storm\\njust like my heartstrings'\n",
        "\n",
        "# We need Token IDs and Attention Mask for inference on the new sentence\n",
        "test_ids = []\n",
        "test_attention_mask = []\n",
        "\n",
        "# Apply the tokenizer\n",
        "encoding = preprocessing(haiku, tokenizer)\n",
        "\n",
        "# Extract IDs and Attention Mask\n",
        "test_ids.append(encoding['input_ids'])\n",
        "test_attention_mask.append(encoding['attention_mask'])\n",
        "test_ids = torch.cat(test_ids, dim = 0)\n",
        "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "\n",
        "# Forward pass, calculate logit predictions\n",
        "with torch.no_grad():\n",
        "  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
        "\n",
        "prediction = 'Good' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 0 else 'Bad'\n",
        "\n",
        "print('Input Haiku: ', haiku)\n",
        "print('Predicted Class: ', prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKJLcOBJoHiv",
        "outputId": "1d0fb3a1-b1fc-4fc7-d064-8bf689538335"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Haiku:  apples of paradise\n",
            "violently shake in the storm\n",
            "just like my heartstrings\n",
            "Predicted Class:  Good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_0 = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/zero_noise.csv\")\n",
        "noise_30 = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/30_noise.csv\")\n",
        "noise_60 = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/60_noise.csv\")\n",
        "\n",
        "noise_0[\"label\"] = 0\n",
        "noise_30[\"label\"] = 1\n",
        "noise_60[\"label\"] = 2\n",
        "\n",
        "test_data = pd.concat([noise_0, noise_30], axis=0)\n",
        "test_data[\"text\"] = test_data.apply(lambda x: \"\\n\".join([x[\"0\"], x[\"1\"], x[\"2\"]]), axis=1)\n",
        "# data = pd.concat([noise_0, noise_30, noise_60], axis=0)"
      ],
      "metadata": {
        "id": "trIIjyuqNQqn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = test_data.text\n",
        "test_label = test_data.label"
      ],
      "metadata": {
        "id": "z9ullex8ogDr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "predictions = []\n",
        "# We need Token IDs and Attention Mask for inference on the new sentence\n",
        "for sample in tqdm(test_text):\n",
        "  test_ids = []\n",
        "  test_attention_mask = []\n",
        "\n",
        "  # Apply the tokenizer\n",
        "  encoding = preprocessing(sample, tokenizer)\n",
        "\n",
        "  # Extract IDs and Attention Mask\n",
        "  test_ids.append(encoding['input_ids'])\n",
        "  test_attention_mask.append(encoding['attention_mask'])\n",
        "  test_ids = torch.cat(test_ids, dim = 0)\n",
        "  test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "\n",
        "  # Forward pass, calculate logit predictions\n",
        "  with torch.no_grad():\n",
        "    output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
        "\n",
        "  predictions.append(np.argmax(output.logits.cpu().numpy()).flatten().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIoqRC6wG01J",
        "outputId": "1a295eab-0346-409c-c3ea-a5acc9532cb9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 4000/4000 [00:47<00:00, 83.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "nKX-1ENELxOc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"accuracy:\", accuracy_score(np.array(predictions), test_label.values))\n",
        "print(\"precision:\", precision_score(np.array(predictions), test_label.values))\n",
        "print(\"recall:\", recall_score(np.array(predictions), test_label.values))\n",
        "print(\"F1:\", f1_score(np.array(predictions), test_label.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AeXW8X3Ml4P",
        "outputId": "fddd3862-f387-4ea4-88ff-d751781b4ec5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.928\n",
            "precision: 0.8715\n",
            "recall: 0.9825253664036077\n",
            "F1: 0.9236883942766296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"gdrive/MyDrive/Colab Notebooks/bert_classifier.pickle\")"
      ],
      "metadata": {
        "id": "OMJ687q8NRJv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"gdrive/MyDrive/Colab Notebooks/output.txt\") as f:\n",
        "  m1_haiku = f.readlines()\n",
        "\n",
        "m1_prompts = [t.split()[0] for t in m1_haiku]\n",
        "m1_haiku = [m1_haiku[i].replace(\"/n\", \"\\n\") for i in range(len(m1_haiku))]\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output2.txt\") as f:\n",
        "  m2_haiku = f.readlines()\n",
        "\n",
        "m2_haiku = [m2_haiku[i].replace(\"/n\", \"\\n\") for i in range(len(m2_haiku))]\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output3.txt\") as f:\n",
        "  m3_haiku = f.readlines()\n",
        "\n",
        "m3_haiku = [m3_haiku[i].replace(\" /n \", \"\\n\") for i in range(len(m3_haiku))]\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output4.txt\") as f:\n",
        "  m4_haiku = f.readlines()\n",
        "\n",
        "m4_haiku = [m4_haiku[i].replace(\" /n \", \"\\n\") for i in range(len(m4_haiku))]\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/loweredcase.txt\") as f:\n",
        "  human_haiku = f.readlines()\n",
        "\n",
        "human_haiku = [haiku[8:].strip().replace(\" / \", \"\\n\") for haiku in human_haiku]"
      ],
      "metadata": {
        "id": "jwJGfz43V3nR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1_haiku[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW-BoDo4YKGw",
        "outputId": "8c721cc1-44dd-44ac-b87e-615241f624b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anger drives passion\\nhatred drives passion walk love\\nlove life joy and joy\\n',\n",
              " 'anger is power\\nis power i love it\\nlove it this is joy\\n',\n",
              " 'anger is power\\nis joy and pleasant\\nlife is joy and joy\\n',\n",
              " \"anger is the answer\\ni'll always be there for\\nyou no excuse me\\n\",\n",
              " 'anger drives louder\\nthan anything and\\nenergy goes to\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2_haiku[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE8WvnYdO21o",
        "outputId": "287f5af0-3059-4b4c-fa5c-20ea984a4e34"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"anger on the face\\nis the enemy of the\\nblack people's death\\n\",\n",
              " 'anger is always\\na distraction and not\\na reason to smile\\n',\n",
              " \"anger doesn't know\\nwhat it is not expect to\\ndo for the party\\n\",\n",
              " 'anger is not so\\nstupid it is very\\nfunny to have her\\n',\n",
              " \"anger is real but\\ni'm not an idiot but\\nno one will fuck me\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m3_haiku[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHNfdNlGO5iB",
        "outputId": "63b0b33b-2fb0-4e14-e62f-8f893127a1f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anger is not an\\nentitlement for a long\\nterm of being raped\\n',\n",
              " 'anger is like you\\ncould be but i will never\\nbe in that mood now\\n',\n",
              " \"anger is the right\\nwhen i'm doing this for\\nthe rest of the world\\n\",\n",
              " 'anger is not in\\nmy mind but no matter what\\nwe will be doing\\n',\n",
              " \"anger is a face\\nof being alive is now\\nit's just that time\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m4_haiku[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x23o0-iNO7X2",
        "outputId": "2de63e82-32f4-4df3-e7a8-8f6468766960"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"anger in my head\\nat work today and this bitch\\nwon't be able to\\n\",\n",
              " 'anger is like the\\nonly way to figure out how\\nto survive the rest\\n',\n",
              " 'anger is the best\\nfor me and i hope everyone\\nin the valley gets blessed\\n',\n",
              " 'anger is that which\\nmeans you can seek for something\\nand be happy\\n',\n",
              " 'anger takes from your\\nheart but you only need your\\npain from killing it\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_haiku[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVjp1lovO9lY",
        "outputId": "e8e46f06-93a8-4319-b8b5-676223c6bfb6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i saw that finger!\\nyes you in the intrepid -\\nwe shall meet again',\n",
              " 'cut into his arm\\na line for each day between\\nchristmas and new year',\n",
              " 'scattered in the ditch\\nlike tiny scraps of blue sky\\nbits of plastic bag',\n",
              " \"to find the beauty\\neven if it's dark and grey\\nthat lightens my day\",\n",
              " 'like a summer breeze\\nblue sky landing in my heart\\na cloud with feathers']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_haiku(haiku):\n",
        "  predictions = []\n",
        "  # We need Token IDs and Attention Mask for inference on the new sentence\n",
        "  for sample in tqdm(haiku):\n",
        "    test_ids = []\n",
        "    test_attention_mask = []\n",
        "\n",
        "    # Apply the tokenizer\n",
        "    encoding = preprocessing(sample, tokenizer)\n",
        "\n",
        "    # Extract IDs and Attention Mask\n",
        "    test_ids.append(encoding['input_ids'])\n",
        "    test_attention_mask.append(encoding['attention_mask'])\n",
        "    test_ids = torch.cat(test_ids, dim = 0)\n",
        "    test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "\n",
        "    # Forward pass, calculate logit predictions\n",
        "    with torch.no_grad():\n",
        "      output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
        "\n",
        "    predictions.append(np.argmax(output.logits.cpu().numpy()).flatten().item())\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "Cdl5r0gQy_0n"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 1 Poems:\", len(m1_haiku))\n",
        "print(\"Model 1 Percent of Good Poems:\", 1 - np.sum(classify_haiku(m1_haiku)) / len(m1_haiku))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSnOOOtvPK51",
        "outputId": "a3c36d3d-c267-4be6-f9d3-122898d3dcdb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Poems: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:11<00:00, 88.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Percent of Good Poems: 0.956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 2 Poems:\", len(m2_haiku))\n",
        "print(\"Model 2 Percent of Good Poems:\", 1 - np.sum(classify_haiku(m2_haiku)) / len(m2_haiku))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiE7C-nYkLop",
        "outputId": "607aa1a8-90f9-4233-95bb-b94ffaa80b8f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 Poems: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 45.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 Percent of Good Poems: 0.979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 3 Poems:\", len(m3_haiku))\n",
        "print(\"Model 3 Percent of Good Poems:\", 1 - np.sum(classify_haiku(m3_haiku)) / len(m3_haiku))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt29cGmsyXto",
        "outputId": "5ef14c71-6c4d-49f6-9e18-9b33c2d675bf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 Poems: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:21<00:00, 45.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 Percent of Good Poems: 0.965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model 4 Poems:\", len(m4_haiku))\n",
        "print(\"Model 4 Percent of Good Poems:\", 1 - np.sum(classify_haiku(m4_haiku)) / len(m4_haiku))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpvXzT_ZQD3t",
        "outputId": "c71cf14e-ed76-417a-adf2-d8b6549d7eb0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 Poems: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:18<00:00, 53.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 Percent of Good Poems: 0.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Human Poems:\", len(human_haiku))\n",
        "print(\"Human Percent of Good Poems:\", 1 - np.sum(classify_haiku(human_haiku)) / len(human_haiku))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXMIBmg7QK6p",
        "outputId": "f5016cb8-f059-4413-89f7-e2828318fc60"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human Poems: 92110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/92110 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 92110/92110 [17:23<00:00, 88.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human Percent of Good Poems: 0.9494191727282597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"gdrive/MyDrive/Colab Notebooks/output_baseline_cnt.txt\") as f:\n",
        "  baseline_haiku = f.readlines()\n",
        "\n",
        "baseline_haiku = [haiku[8:].strip().replace(\" /n \", \"\\n\") for haiku in baseline_haiku]"
      ],
      "metadata": {
        "id": "IaJcOMe3EPfC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"Baseline Poems:\", len(baseline_haiku))\n",
        "print(\"Baseline Percent of Good Poems:\", 1 - np.sum(classify_haiku(baseline_haiku)) / len(baseline_haiku))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-1ZwYy6IYXe",
        "outputId": "7aeb0144-42d0-4f4a-9c30-816ecc38aa99"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Poems: 992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 992/992 [02:56<00:00,  5.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Percent of Good Poems: 0.9808467741935484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"gdrive/MyDrive/Colab Notebooks/bert_classifier.pickle\", map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "EHHDyBsSFU0r"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_haiku[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GAfJHl5rFMui",
        "outputId": "7a9f7827-5138-4f42-d34b-55f391d84b2d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"anger is an\\nawful person but it's all good\\nand i wanna do\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_haiku[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ucQwyDXmEjzV",
        "outputId": "4050d268-e988-48b7-afc0-16a25b01c4bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"4,8,5 | anger is an /n awful person but it's all good /n and i wanna do \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structure Evaluation"
      ],
      "metadata": {
        "id": "HkTjTbQY4LYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74pwJ93L4SVl",
        "outputId": "73ad507e-291a-4e9d-cce8-828db91fa959"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"gdrive/MyDrive/Colab Notebooks/output_baseline_cnt.txt\") as f:\n",
        "  output0_cnt = f.readlines()\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output_cnt.txt\") as f:\n",
        "  output1_cnt = f.readlines()\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output2_cnt.txt\") as f:\n",
        "  output2_cnt = f.readlines()\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output3_cnt.txt\") as f:\n",
        "  output3_cnt = f.readlines()\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output4_cnt.txt\") as f:\n",
        "  output4_cnt = f.readlines()\n",
        "\n",
        "with open(\"gdrive/MyDrive/Colab Notebooks/output_human_cnt.txt\") as f:\n",
        "  output_human_cnt = f.readlines()"
      ],
      "metadata": {
        "id": "B56FkON2mC_J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(count):\n",
        "  score = 0 \n",
        "  if count[0] == 5:\n",
        "    score += 2\n",
        "  if count[1] == 7:\n",
        "    score += 2\n",
        "  if count[2] == 5:\n",
        "    score += 2\n",
        "  return score\n",
        "\n",
        "def get_score(counts):\n",
        "  counts = [cnt[:5].split(\",\") for cnt in counts]\n",
        "  bad_counts = [count for count in counts if \"\" in count]\n",
        "  n_bad = len(bad_counts)\n",
        "  good_counts = counts\n",
        "  # good_counts = [count for count in counts if count not in bad_counts]\n",
        "  good_counts = [[int(c) if c.isnumeric() else 0 for c in count] for count in good_counts]\n",
        "  scores = list(map(score, good_counts))\n",
        "\n",
        "  return n_bad, np.mean(scores)"
      ],
      "metadata": {
        "id": "dJ9BCQoon-Am"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_bad0, score0 = get_score(output0_cnt)\n",
        "n_bad1, score1 = get_score(output1_cnt)\n",
        "n_bad2, score2 = get_score(output2_cnt)\n",
        "n_bad3, score3 = get_score(output3_cnt)\n",
        "n_bad4, score4 = get_score(output4_cnt)\n",
        "n_bad_human, score_human = get_score(output_human_cnt)"
      ],
      "metadata": {
        "id": "nffIy29GraVH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score0, score1, score2, score3, score4, score_human"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oKk71Wn5Zjl",
        "outputId": "cb53b727-4540-4447-c7e3-d0ebdb2a72d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.6875,\n",
              " 2.6264308012486994,\n",
              " 3.468937875751503,\n",
              " 3.4170854271356785,\n",
              " 2.768920282542886,\n",
              " 3.093236347844968)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title(\"Structure Score (0 to 6)\")\n",
        "\n",
        "scores = [score1, score2, score3, score4, score_human]\n",
        "colors=['blue', 'blue', 'blue', 'blue', 'red']\n",
        "labels = [\"model1\", \"model2\", \"model3\", \"model4\", \"baseline\"]\n",
        "\n",
        "plt.bar(labels, scores, width=0.5, color=colors)\n",
        "\n",
        "# plt.xlabel([\"model1\", \"model2\", \"model3\", \"model4\", \"baseline\"], colors)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "D2NiZpBo6F9_",
        "outputId": "7a24127c-d236-4c02-d09a-9cfcf23cee17"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCkPrU046VCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}